{
  "u_transform_q_o_down_proj": {
    "global_transform": false,
    "groups": [
      {
        "call_args": {},
        "ignore": [],
        "module_targets": [
          "weight"
        ],
        "targets": [
          "re:.*.attn.q_proj$",
          "re:.*.attn.o_proj$",
          "re:.*.mlp.down_proj$"
        ]
      }
    ],
    "transform_creation_args": {
      "dtype": "torch.bfloat16",
      "size": 2048
    },
    "transform_type": "random-hadamard"
  }
}